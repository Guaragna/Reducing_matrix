{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e8c38eb1-57e6-4179-b208-fe0c1fd58521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Mara/Documents/Mestrado/Pesquisa/param_matrix_mult'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2199279e-c95d-442e-858e-29a32dc130bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import flwr as fl\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from collections import OrderedDict\n",
    "from typing import List, Tuple\n",
    "from flwr.common import Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d2ced0-43bd-4e0a-bc05-ee59d2ff67c0",
   "metadata": {},
   "source": [
    "Importando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "34940eda-610a-4a51-b364-b030aff1a3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = datasets.MNIST(root='./datasets', train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = datasets.MNIST(root='./datasets', train=False, transform=transforms.ToTensor(), download=True)\n",
    "mnist_train_slice = list(mnist_train)[0:1000]\n",
    "mnist_test_slice = list(mnist_test)[0:1000]\n",
    "train_loader = DataLoader(mnist_train, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503b98f4-84af-42a8-9199-a4c73dc5dfc2",
   "metadata": {},
   "source": [
    "Classe do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a87d98e0-dbf0-46ee-a62c-5a0cd5c9edb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(784, 500)\n",
    "        self.linout = nn.Linear(500, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        l2_inp = self.lin1(x)\n",
    "        l2_relu = torch.max(torch.zeros_like(l2_inp), l2_inp)\n",
    "        return self.linout(l2_relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beae993-b21f-4019-9db8-2fd4f6ff1068",
   "metadata": {},
   "source": [
    "#### Aprendizado Centralizado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451320a7-d0e7-4016-b8f0-4a757ab81511",
   "metadata": {},
   "source": [
    "Treinando o modelo centralizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "58c810f2-b07b-49f2-afb9-ab35c327045e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5bec54efa6d4a02b7257968db24bc36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1321224727bf43e6a5ea0a1e1313c728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9624999761581421\n"
     ]
    }
   ],
   "source": [
    "##Training\n",
    "#Instantiate model\n",
    "model = MNIST_MLP()\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1.1)\n",
    "\n",
    "for epoch in range(1):\n",
    "    #Iterate over the train set minibatchs\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        #Zero out the gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #Forward pass\n",
    "        x = images.view(-1, 28*28)\n",
    "        y = model(x)\n",
    "        loss = criterion(y, labels)\n",
    "\n",
    "        #Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "##Testing\n",
    "correct = 0\n",
    "total = len(mnist_test)\n",
    "\n",
    "with torch.no_grad():\n",
    "    #Iterate through the test set minibacth\n",
    "    for images, labels in tqdm(test_loader):\n",
    "        #Forward pass\n",
    "        x = images.view(-1, 28*28)\n",
    "        y = model.forward(x)\n",
    "        #print(y)\n",
    "        predictions = torch.argmax(y, dim=1)\n",
    "        correct += torch.sum((predictions==labels).float())\n",
    "        \n",
    "print('Test accuracy: {}'.format(correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c04739a-0e37-4ffa-85bf-da0f7a828497",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Salvando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3e4bd9fe-46ca-4905-a357-347ef14e4cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    " file = \"modelo_mlp.pth\"\n",
    "# torch.save(model.state_dict(), file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6b04b6-a610-40d0-b7f3-d22d48b013ab",
   "metadata": {},
   "source": [
    "Carregando modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "09e4f867-0887-4535-a1b2-504216fed011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MNIST_MLP()\n",
    "net.load_state_dict(torch.load(file))\n",
    "#net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37559d2e-bee6-4561-afea-b55e19f5b377",
   "metadata": {},
   "source": [
    "Carregando o mesmo modelo novamente para mudar os pesos, e usar os pesos originais para manter escala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "8d61bc29-d139-460a-96b5-e01f8e4076c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2 = MNIST_MLP()\n",
    "net2.load_state_dict(torch.load(file))\n",
    "#net2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e3192988-6d91-40fc-bb85-1b1bbe4b7bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNIST_MLP(\n",
       "  (lin1): Linear(in_features=784, out_features=500, bias=True)\n",
       "  (linout): Linear(in_features=500, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd66d806-8c07-40c3-9190-a38008e9ca4b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Agregando os pesos pelos parametros(colunas) e samples(linhas) atraves da mediana/media.\n",
    "Depois multiplicando as agregacoes para reconstruir o formato da matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b3a7fb23-34c6-4571-8cdb-8e408a42cf3a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for p in net2.parameters():\n",
    "    if p.dim() == 2:\n",
    "        with torch.no_grad():\n",
    "            med_feat = np.asarray(p.median(axis=0)[0])\n",
    "            med_peso = np.asarray(p.median(axis=1)[0])\n",
    "            p.data = torch.from_numpy(np.asarray(med_feat)*np.asarray(med_peso).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b24497e-e652-42c5-9309-f6b5639611f0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Mantendo escala dos parametros originais (Em muitos casos nao muda nada, os parametros sao invariantes a escala)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "fed6f88f-08a3-4cc2-9b52-0564dd66f87f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for p1, p2 in zip(net.parameters(), net2.parameters()):\n",
    "        if p2.dim() == 2:\n",
    "            p2.mul_(p1.norm()/p2.norm())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aff0768-e148-40fc-85f2-21ee4e9b22dc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Tentativa de manter somente media/mediana dos pesos pelos features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "31aa8eed-2dcc-4fd4-b06a-831e54efc056",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for p in net2.parameters():\n",
    "    if p.dim() == 2:\n",
    "        with torch.no_grad():\n",
    "            med_param_l1 = np.asarray(p.median(axis=1)[0])\n",
    "            dim = p.size()[1]\n",
    "            p.data = torch.from_numpy(np.repeat(med_param_l1, dim).reshape(-1, dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4b1898-a014-42dd-b58a-d8b5fc09c99e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Tentativa de manter somente media/mediana dos features pelos pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "bb3dc3c4-59c9-45dd-bebc-1ff1592825dc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for p in net2.parameters():\n",
    "    if p.dim() == 2:\n",
    "        with torch.no_grad():\n",
    "            med_param_l1 = np.asarray(p.median(axis=0)[0])\n",
    "            dim = p.size()[0]\n",
    "            p.data = torch.from_numpy(np.tile(med_param_l1, (dim,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "54d6a873-f725-497e-91a4-284c1a3e58d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 784])\n",
      "torch.Size([500])\n",
      "torch.Size([10, 500])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in net2.parameters():\n",
    "    print(p.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c3f8d9-7c5c-4c0e-8311-7d11c6859aa0",
   "metadata": {},
   "source": [
    "Testando com medias por grupos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e994c37-8258-426b-91bd-e2e38f34ff0e",
   "metadata": {},
   "source": [
    "Criando funcao para juntar n elementos e computar a media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "2e7a0833-050a-4962-8207-da279d72e9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_matrix(arr, n):\n",
    "    with torch.no_grad():\n",
    "        if type(arr) != \"numpy.ndarray\":\n",
    "            arr = np.asarray(arr)\n",
    "        # Number of complete groups of n elements in each row\n",
    "        full_groups_count = arr.shape[1] // n\n",
    "        \n",
    "        # Reshape the array to split each row into subarrays of n elements where possible\n",
    "        reshaped_arr = arr[:, :full_groups_count * n].reshape(arr.shape[0], -1, n)\n",
    "        \n",
    "        # Calculate the mean along the new innermost axis for full groups\n",
    "        mean_arr = np.median(reshaped_arr, axis=2)\n",
    "        \n",
    "        # Check for remaining elements and calculate their mean if they exist\n",
    "        rest = arr.shape[1] % n\n",
    "        if rest != 0:\n",
    "            # Slicing to get the remaining elements\n",
    "            remaining_elements = arr[:, full_groups_count * n:]\n",
    "            remaining_means = np.mean(remaining_elements, axis=1, keepdims=True)\n",
    "            \n",
    "            # Concatenate the means of full groups with the mean of remaining elements\n",
    "            mean_arr = np.concatenate((mean_arr, remaining_means), axis=1)\n",
    "        \n",
    "    return mean_arr, rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "df39357b-9327-4c5c-b8e3-e89f8b1b4d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_matrix(arr, n, r):\n",
    "    with torch.no_grad():\n",
    "        tam = arr.shape[0]\n",
    "        if r == 0:\n",
    "            matrix = arr.repeat(n).reshape(tam, -1)\n",
    "        else:\n",
    "            #replica os grupos fechados de medias\n",
    "            grupo = arr[:,:-1].repeat(n).reshape(tam, -1)\n",
    "            \n",
    "            #replica o resto\n",
    "            resto = arr[:,-1].repeat(r).reshape(tam, -1)\n",
    "            matrix = np.concatenate((grupo, resto), axis = 1)\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "d1a53ac1-fa5e-486a-987a-ae13090ec8c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "2\n",
      "10\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for p in net2.parameters():\n",
    "    if p.dim() == 2:\n",
    "        tam = p.size(1)\n",
    "        n = round(p.size(1)*0.006/2)\n",
    "        print(p.size(0))\n",
    "        print(n)\n",
    "        if n != 0 or n != 1:\n",
    "            medias, resto = reduce_matrix(p, n)\n",
    "            p.data = torch.from_numpy(resize_matrix(medias, n, resto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "6f29683a-5bf4-4f6a-b1aa-5f2fd77d9355",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "n = 4\n",
    "with torch.no_grad():\n",
    "    if type(t) != \"numpy.ndarray\":\n",
    "        arr = np.asarray(t)\n",
    "    # Number of complete groups of n elements in each row\n",
    "    full_groups_count = arr.shape[1] // n\n",
    "    \n",
    "    # Reshape the array to split each row into subarrays of n elements where possible\n",
    "    reshaped_arr = arr[:, :full_groups_count * n].reshape(arr.shape[0], -1, n)\n",
    "    \n",
    "    # Calculate the mean along the new innermost axis for full groups\n",
    "    mean_arr = np.median(reshaped_arr, axis=2)\n",
    "    \n",
    "    # Check for remaining elements and calculate their mean if they exist\n",
    "    rest = arr.shape[1] % n\n",
    "    if rest != 0:\n",
    "        # Slicing to get the remaining elements\n",
    "        remaining_elements = arr[:, full_groups_count * n:]\n",
    "        remaining_means = np.mean(remaining_elements, axis=1, keepdims=True)\n",
    "    \n",
    "        # Concatenate the means of full groups with the mean of remaining elements\n",
    "        mean_arr = np.concatenate((mean_arr, remaining_means), axis=1)\n",
    "         \n",
    "    # replica os grupos fechados de medias\n",
    "    tam = mean_arr.shape[0]\n",
    "    grupo = mean_arr[:,:-1].repeat(n).reshape(tam, -1)\n",
    "\n",
    "    # replica o resto\n",
    "    resto = mean_arr[:,-1].repeat(rest).reshape(tam, -1)\n",
    "\n",
    "    # concatena\n",
    "    matrix = np.concatenate((grupo, resto), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18e857d-48b4-46c4-bd50-bc8913d3de66",
   "metadata": {},
   "source": [
    "Testando novos parametros no caso centralizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "6d1706a1-cf79-44e2-860d-f99dbcf23579",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9458)\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    #Iterate through the test set minibacth\n",
    "    for images, labels in test_loader:\n",
    "        #Forward pass\n",
    "        x = images.view(-1, 28*28)\n",
    "        y = net2.forward(x)\n",
    "        #print(y)\n",
    "        predictions = torch.argmax(y, dim=1)\n",
    "        correct += torch.sum((predictions==labels).float())\n",
    "print(correct/len(mnist_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b606df-d68a-41f4-8235-73b8b60ae8cc",
   "metadata": {},
   "source": [
    "#### Aprendizado Federado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553da838-5af8-4fd4-bb36-17c53a745da4",
   "metadata": {},
   "source": [
    "Setando onde vao ser realizadas as computacoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "f857df85-c77b-4a6e-8d2a-bfc32cfa5e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30721d5c-6449-44f9-a58d-01eb3a0917e5",
   "metadata": {},
   "source": [
    "Separando os dados por cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "db2917da-574a-4ecc-b87d-2f27ab3b9a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 10\n",
    "BATCH_SIZE = 32\n",
    "partition_size = len(mnist_train_slice) // NUM_CLIENTS\n",
    "lengths = [partition_size] * NUM_CLIENTS\n",
    "datasets = random_split(mnist_train_slice, lengths, torch.Generator().manual_seed(42))\n",
    "\n",
    "# Create train/val for each partition and wrap it into DataLoader\n",
    "trainloaders = []\n",
    "valloaders = []\n",
    "for ds in datasets:\n",
    "    len_val = len(ds) // 10\n",
    "    len_train = len(ds) - len_val\n",
    "    lengths = [len_train, len_val]\n",
    "    ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
    "    trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "    valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "testloader = DataLoader(mnist_test_slice, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2659cc6f-0afb-4fc7-bc4d-b6db72146b2d",
   "metadata": {},
   "source": [
    "Define funcao de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "8217abb4-2abf-4a5e-8e4a-536642bdb0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, epochs: int, verbose=False):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            images = images.view(-1, 28*28)\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "    if verbose:\n",
    "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            images = images.view(-1, 28*28)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a05b44c-a4c3-4f0c-ac1f-d293eca66e53",
   "metadata": {},
   "source": [
    "Criando classe do cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "8b14ece3-4457-4268-b8e2-805fe6ee5ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters(net) -> List[np.ndarray]: \n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "    \n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, net, trainloader, valloader):\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=1)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f5b30c-b9d5-438f-9aa4-6e7ac1a45fe4",
   "metadata": {},
   "source": [
    "Cria funcao para gerar instancias do FlowerClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "dc375134-ba43-4c9d-8d66-96a696c853ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_fn(cid: str) -> FlowerClient:\n",
    "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
    "\n",
    "    # Load model\n",
    "    net = MNIST_MLP().to(DEVICE)\n",
    "\n",
    "    # Note: each client gets a different trainloader/valloader, so each client\n",
    "    # will train and evaluate on their own unique data\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "\n",
    "    # Create a single Flower client representing a single organization\n",
    "    return FlowerClient(net, trainloader, valloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48da25a-5ffa-4a07-b5b6-30267da06ff0",
   "metadata": {},
   "source": [
    "Funcao para mostrar acuracia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "ab84e119-c52f-4e82-83e1-7f5f82bc305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    # Multiply accuracy of each client by number of examples used\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "\n",
    "    # Aggregate and return custom metric (weighted average)\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db68e301-2616-4eb6-a680-222fcb2a984b",
   "metadata": {},
   "source": [
    "Seta a estratedia de agregacao e treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "11638095-8596-4dc3-9241-931a2283a5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1.0, # Sample 100% of available clients for training\n",
    "    fraction_evaluate=0.5, # Sample 50% of available clients for evaluation\n",
    "    min_fit_clients=10, # Never sample less than 10 clients for training\n",
    "    min_evaluate_clients=5, # Never sample less than 5 clients for evaluation\n",
    "    min_available_clients=10, # Wait until all 10 clients are available\n",
    "    evaluate_metrics_aggregation_fn=weighted_average,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc2e255-a61d-4ec4-bb2f-8b8e527030bd",
   "metadata": {},
   "source": [
    "Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "ae988097-6256-4d0d-96b1-0baed63e71d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=10, no round_timeout\n",
      "2024-04-27 16:29:39,490\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'memory': 2725711872.0, 'node:127.0.0.1': 1.0, 'CPU': 4.0, 'object_store_memory': 1362855936.0, 'node:__internal_head__': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      No `client_resources` specified. Using minimal resources for clients.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 4 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[2m\u001b[36m(pid=27538)\u001b[0m 2024-04-27 16:29:47.642325: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[2m\u001b[36m(pid=27538)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Evaluating initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=27540)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
      "\u001b[2m\u001b[36m(pid=27539)\u001b[0m 2024-04-27 16:29:47.636637: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=27539)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=27540)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=27540)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=27540)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=27540)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=27540)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=27540)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=27540)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=27537)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=27538)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=27538)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=27538)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 33x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=27538)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=27538)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 28x across cluster]\u001b[0m\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 10 rounds in 31.96s\n",
      "\u001b[92mINFO \u001b[0m:      History (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t('\\tround 1: 0.21507327556610112\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 2: 0.19945120334625244\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 3: 0.17114811420440673\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 4: 0.15345122337341308\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 5: 0.12797161579132083\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 6: 0.11112957596778869\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 7: 0.10416423082351685\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 8: 0.09715561628341673\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 9: 0.09623378753662108\\n'\n",
      "\u001b[92mINFO \u001b[0m:      \t '\\tround 10: 0.06966585874557493\\n')History (metrics, distributed, evaluate):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, 0.54),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (2, 0.5),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (3, 0.72),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (4, 0.6),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (5, 0.7),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (6, 0.76),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (7, 0.6799999999999999),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (8, 0.74),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (9, 0.76),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (10, 0.8400000000000001)]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "History (loss, distributed):\n",
       "('\\tround 1: 0.21507327556610112\\n'\n",
       " '\\tround 2: 0.19945120334625244\\n'\n",
       " '\\tround 3: 0.17114811420440673\\n'\n",
       " '\\tround 4: 0.15345122337341308\\n'\n",
       " '\\tround 5: 0.12797161579132083\\n'\n",
       " '\\tround 6: 0.11112957596778869\\n'\n",
       " '\\tround 7: 0.10416423082351685\\n'\n",
       " '\\tround 8: 0.09715561628341673\\n'\n",
       " '\\tround 9: 0.09623378753662108\\n'\n",
       " '\\tround 10: 0.06966585874557493\\n')History (metrics, distributed, evaluate):\n",
       "{'accuracy': [(1, 0.54),\n",
       "              (2, 0.5),\n",
       "              (3, 0.72),\n",
       "              (4, 0.6),\n",
       "              (5, 0.7),\n",
       "              (6, 0.76),\n",
       "              (7, 0.6799999999999999),\n",
       "              (8, 0.74),\n",
       "              (9, 0.76),\n",
       "              (10, 0.8400000000000001)]}"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=10),\n",
    "    strategy=strategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "65ed037c-c507-4bbd-afbb-aa6e05ea708e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "dc83ed02-747c-4175-87a3-51f946ae43d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.tile(a, (10, 1))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "214771ac-4e98-4323-a803-17fcb36fdc46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "       [3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
       "       [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.repeat(a, 10).reshape(-1,10)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "d43f2e05-d733-49fc-af7f-e9684bdfd693",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.Tensor([[0,1,2,3,12,13],\n",
    "                  [4,5,6,7,14,15],\n",
    "                  [8,9,10,11,16,17]]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f03674-f463-408a-9627-fcd5184f7210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduz(tensor, n, agg):\n",
    "    if agg == \"feature\":\n",
    "        for t in np.transpose(tensor):\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "53e6e8ee-45e3-4c41-869e-07f923754a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_of_elements(arr, n):\n",
    "    if type(arr) != \"numpy.ndarray\":\n",
    "        arr = np.asarray(arr)\n",
    "    # Number of complete groups of n elements in each row\n",
    "    full_groups_count = arr.shape[1] // n\n",
    "    \n",
    "    # Reshape the array to split each row into subarrays of n elements where possible\n",
    "    reshaped_arr = arr[:, :full_groups_count * n].reshape(arr.shape[0], -1, n)\n",
    "    \n",
    "    # Calculate the mean along the new innermost axis for full groups\n",
    "    mean_arr = np.mean(reshaped_arr, axis=2)\n",
    "    \n",
    "    # Check for remaining elements and calculate their mean if they exist\n",
    "    if arr.shape[1] % n != 0:\n",
    "        # Slicing to get the remaining elements\n",
    "        remaining_elements = arr[:, full_groups_count * n:]\n",
    "        remaining_means = np.mean(remaining_elements, axis=1, keepdims=True)\n",
    "        \n",
    "        # Concatenate the means of full groups with the mean of remaining elements\n",
    "        mean_arr = np.concatenate((mean_arr, remaining_means), axis=1)\n",
    "    \n",
    "    return mean_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52ffe6b-46b1-46cb-ae68-cb435d609704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example array with a row that can't be evenly divided by n\n",
    "array = np.array([[0, 1, 2, 3, 4], [4, 5, 6, 7, 8]])\n",
    "\n",
    "# Call the function with n=2\n",
    "result = mean_of_elements(array, 2)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "ddac584e-7bf5-48b3-b162-d4f8b744ece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n =mean_of_elements(t,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "615497f1-79ff-4a7b-9edc-b9dd17f9c37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.      ,  9.333333],\n",
       "       [ 5.      , 12.      ],\n",
       "       [ 9.      , 14.666667]], dtype=float32)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "6f3f3124-6f7c-44c1-a635-64a4d39950de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.      ,  1.      ,  1.      ,  9.333333,  9.333333,  9.333333],\n",
       "       [ 5.      ,  5.      ,  5.      , 12.      , 12.      , 12.      ],\n",
       "       [ 9.      ,  9.      ,  9.      , 14.666667, 14.666667, 14.666667]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.repeat(3).reshape(-1,3*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "bb637212-5d4f-429c-b21b-c2a5b50c13b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4],\n",
       "       [4, 5, 6, 7, 8]])"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "a72f985b-60bc-4600-898d-ee6674e816bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4],\n",
       "       [4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7, 8, 8]])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((array[:,:-1].repeat(3).reshape(2,-1),array[:,-1].repeat(2).reshape(2,-1)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "00aa0eab-d9a5-4594-b575-9080e732914c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 4],\n",
       "       [8, 8]])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array[:,-1].repeat(2).reshape(2,-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
